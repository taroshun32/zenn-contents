---
title: "Faster Whisperã¨AWS SageMakerã‚’æ´»ç”¨ã—ã¦GPUã§ã®é«˜é€Ÿæ–‡å­—èµ·ã“ã—ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹"
emoji: "ğŸ’¬"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["ai", "whisper", "sagemaker", "aws", "python" ]
publication_name: "nextbeat"
published: true
---

## æ¦‚è¦

æœ€è¿‘ã®éŸ³å£°èªè­˜æŠ€è¡“ã®é€²æ­©ã¯ã™ã”ã„ã§ã™ã­ï¼
ç‰¹ã«OpenAIã®æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹Whisper large-v3ã¯ã€æ—¥æœ¬èªã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã§ã‚‚ã‹ãªã‚Šã®é«˜ç²¾åº¦ã§æ–‡å­—èµ·ã“ã—ã‚’è¡Œã†ã“ã¨ãŒã§ãã€APIã‚‚å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚
ãŸã ã—ç°¡å˜ã«ä½¿ç”¨ã§ãæ±ç”¨æ€§ã‚‚é«˜ã„ä¸€æ–¹ã§ã€å¤§é‡ã«ä½¿ç”¨ã™ã‚‹å ´åˆã®é«˜ã‚³ã‚¹ãƒˆã‚„ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã®æ‡¸å¿µã‚‚ã‚ã‚‹ãŸã‚ã€ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§åŠ¹ç‡ã‚ˆãé«˜ç²¾åº¦ãªæ–‡å­—èµ·ã“ã—ã‚’å®Ÿç¾ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ãŒå¤šæ•°é–‹ç™ºã•ã‚Œã¦ã„ã¾ã™ã€‚

ä»Šå›ã¯ã€ãã®ä¸­ã§ã‚‚GPUã‚’ä½¿ç”¨ã—ãŸé«˜é€Ÿæ¨è«–ãŒå¯èƒ½ãªã€ŒFaster Whisperã€ã‚’ç”¨ã„ã¦ã€AWS SageMakerã§ã‚«ã‚¹ã‚¿ãƒ æ–‡å­—èµ·ã“ã—ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’æ§‹ç¯‰ã—ã¦ã¿ãŸã®ã§ã€æ‰‹é †ã‚’è§£èª¬ã—ã¦ã„ããŸã„ã¨æ€ã„ã¾ã™ã€‚

å®Ÿè£…ã‚³ãƒ¼ãƒ‰ã¯ä»¥ä¸‹ã®ãƒªãƒã‚¸ãƒˆãƒªã«ã‚ã‚Šã¾ã™ã€‚
é †ç•ªé€šã‚ŠJupyterNotebookã‚’å®Ÿè¡Œã™ã‚‹ã¨å•é¡Œãªãå‹•ä½œã™ã‚‹ã¯ãšã§ã™ã€‚
https://github.com/taroshun32/whisper-gpu-transcribe-with-sagemaker

## Faster Whisperã¨ã¯

Faster Whisperã¯OpenAIã®Whisperãƒ¢ãƒ‡ãƒ«ã‚’åŸºã«ã€ç¿»è¨³ãƒ¢ãƒ‡ãƒ«ç”¨ã®é«˜é€Ÿæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ã§ã‚ã‚‹CTranslate2ã‚’ä½¿ç”¨ã—ã¦å†å®Ÿè£…ã•ã‚ŒãŸã‚‚ã®ã§ã™ã€‚
å…¬å¼ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ã‚ˆã‚‹ã¨ã€åŒç­‰ã®ç²¾åº¦ã‚’ä¿ã¡ãªãŒã‚‰ã‚‚OpenAIã®Whisperã‚ˆã‚Šã‚‚æœ€å¤§4å€é«˜é€Ÿã§ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚‚å°‘ãªã„ã¨ã•ã‚Œã¦ã„ã¾ã™ã€‚

https://github.com/SYSTRAN/faster-whisper

## AWS SageMakerã¨ã¯

AWS SageMakerã¯ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ãƒ»ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ»ãƒ‡ãƒ—ãƒ­ã‚¤ã‚’å®¹æ˜“ã«è¡Œãˆã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚ŒãŸå®Œå…¨ãƒãƒãƒ¼ã‚¸ãƒ‰å‹ã®æ©Ÿæ¢°å­¦ç¿’ã‚µãƒ¼ãƒ“ã‚¹ã§ã™ã€‚

https://aws.amazon.com/jp/sagemaker/

ä»Šå›ã¯æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¯è¡Œã‚ãšã€GPUã‚’ä½¿ç”¨ã—ãŸæ¨è«–ã‚’è¡Œã†ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®æ§‹ç¯‰ã«ç„¦ç‚¹ã‚’å½“ã¦ã¾ã™ã€‚
ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ãƒ‡ãƒ—ãƒ­ã‚¤ã«ã¯ä¸»ã«ä»¥ä¸‹ã®3ã¤ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒã‚ã‚Šã¾ã™ã€‚

- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–
- éåŒæœŸæ¨è«–
- ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹æ¨è«–

ä»Šå›ã¯ä»¥ä¸‹ã®ç†ç”±ã‹ã‚‰ã€ŒéåŒæœŸæ¨è«–ã€ã‚’æ¡ç”¨ã—ã€æ§‹ç¯‰ã—ã¦ã„ãã¾ã™ã€‚

- GPUã‚’ä½¿ç”¨ï¼ˆã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹æ¨è«–ã¯éå¯¾å¿œï¼‰
- ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒ«è¨­å®šã«ã‚ˆã‚Šã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒãªã„æ™‚ã«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’0ã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚¤ãƒ³ã§ãã‚‹ãŸã‚ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–ã¨æ¯”ã¹ã¦ã‚³ã‚¹ãƒˆã‚’æŠ‘ãˆã‚‹ã“ã¨ãŒå¯èƒ½

## å‰ææ¡ä»¶

ã“ã®è¨˜äº‹ã§ã¯ã€ä»¥ä¸‹ã®å„ç¨®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ä½¿ç”¨ã—ã¦æ§‹ç¯‰ã‚’è¡Œã„ã¾ã™ã€‚
(å¾Œè¿°ã™ã‚‹SageMakerå…¬å¼ã®Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã«åˆã‚ã›ã¦é¸å®šã—ã¦ã„ã¾ã™)

- Python: 3.10
- CUDA: 11.8
- PyTorch: 2.20
- Faster Whisper: 1.0.2 (CTranslate2: 3.24.0)

â€»ã“ã“ã§ã¯è©³ã—ãè§£èª¬ã—ã¾ã›ã‚“ãŒã€PyTorchã¨GPU/CUDAå‘¨ã‚Šã®ä¾å­˜é–¢ä¿‚ã¯è¤‡é›‘ãªã®ã§ãƒãƒ¼ã‚¸ãƒ§ãƒ³é¸å®šã¯æ…é‡ã«è¡Œã„ã¾ã—ã‚‡ã†ã€‚

## æ§‹ç¯‰æ‰‹é †

ã§ã¯å®Ÿéš›ã«æ§‹ç¯‰ã—ã¦ã„ãã¾ã™ã€‚

::::message
ä»Šå›ã¯ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆã‚³ãƒ³ã‚½ãƒ¼ãƒ«ä¸Šã§ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç«‹ã¡ä¸Šã’ã¦JupyterLabä¸Šã§æ§‹ç¯‰ã™ã‚‹å‰æã§è§£èª¬ã—ã¦ã„ãã¾ã™ã€‚ï¼ˆ`ml.t3.medium`ã§å¤§ä¸ˆå¤«ã§ã™ï¼‰
ä½¿ç”¨ã™ã‚‹IAMãƒ­ãƒ¼ãƒ«ã®ä¾‹ã«é–¢ã—ã¦ã¯ã€ä»¥ä¸‹ã®Terraformã‚³ãƒ¼ãƒ‰ã‚’å‚ç…§ãã ã•ã„ã€‚

:::details SageMakerç”¨ã®IAMãƒ­ãƒ¼ãƒ«
â€» ä»Šå›ã¯ã‚µãƒ³ãƒ—ãƒ«ãªã®ã§å…¨ã¦FullAccessã‚’ä»˜ä¸ã—ã¦ã¾ã™ã€‚
```tf
resource "aws_iam_role" "example_role" {
  name = "ExampleRole"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Action = "sts:AssumeRole"
        Effect = "Allow"
        Principal = {
          Service = ["sagemaker.amazonaws.com"]
        }
      },
    ]
  })
}

# SageMaker Full Access
resource "aws_iam_role_policy_attachment" "sagemaker_full_access" {
  role       = aws_iam_role.example_role.name
  policy_arn = "arn:aws:iam::aws:policy/AmazonSageMakerFullAccess"
}

# S3 Full Access
resource "aws_iam_role_policy_attachment" "s3_full_access" {
  role       = aws_iam_role.example_role.name
  policy_arn = "arn:aws:iam::aws:policy/AmazonS3FullAccess"
}

# ECR Full Access
resource "aws_iam_role_policy_attachment" "ecr_full_access" {
  role       = aws_iam_role.example_role.name
  policy_arn = "arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryFullAccess"
}

# CloudWatch Full Access
resource "aws_iam_role_policy_attachment" "cloudwatch_full_access" {
  role       = aws_iam_role.example_role.name
  policy_arn = "arn:aws:iam::aws:policy/CloudWatchFullAccess"
}
```
:::
::::


ä¸»ã«ä»¥ä¸‹ã®å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨å®Ÿè£…ä¾‹ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’å‚è€ƒã«ã•ã›ã¦ã„ãŸã ãã¾ã—ãŸã€‚ï¼ˆYouTubeã§å‹•ç”»ã‚‚å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ï¼‰

https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/async-inference.html
https://github.com/aws-samples/aws-ml-jp/tree/main/sagemaker/sagemaker-inference/inference-tutorial

### 1. ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ¡ãƒ¼ã‚¸ã®ä½œæˆ

ä»Šå›ã¯ã€SageMakerãŒå…¬å¼ã«æä¾›ã—ã¦ã„ã‚‹PyTorchã®æ¨è«–ç”¨Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãƒ™ãƒ¼ã‚¹ã«ä½¿ç”¨ã—ã¾ã™ã€‚

https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg-ecr-paths/ecr-ap-northeast-1.html#pytorch-ap-northeast-1.title

ä»¥ä¸‹ã®Pythonã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ã§ã€å¯¾å¿œã™ã‚‹ECRãƒ¬ã‚¸ã‚¹ãƒˆãƒªãƒ‘ã‚¹ã‚’å–å¾—ã§ãã¾ã™ã€‚

```py
from sagemaker import image_uris
image_uris.retrieve(framework='pytorch',region='ap-northeast-1',version='2.2.0',py_version='py310',image_scope='inference', instance_type='ml.g4dn.xlarge')
```

Faster Whisperã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦ãªãŸã‚ã€ä»¥ä¸‹ã®Dockerfileã‚’ä½œæˆã—ã¾ã™ã€‚
(â€»è¨˜äº‹åŸ·ç­†ç¾åœ¨SageMakerã®æ¨è«–ç”¨ã‚¤ãƒ¡ãƒ¼ã‚¸ã¯CUDA12ã«å¯¾å¿œã—ã¦ã„ãªã„ãŸã‚ã€CTranslate2ã¯ 3.24.0 ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™)

```docker:Dockerfile
FROM 763104351884.dkr.ecr.ap-northeast-1.amazonaws.com/pytorch-inference:2.2.0-gpu-py310

# faster-whisper ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
RUN pip install faster-whisper==1.0.2
RUN pip install --force-reinstall ctranslate2==3.24.0
```

Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãƒ“ãƒ«ãƒ‰ã—ã€è‡ªåˆ†ã®AWSã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ECRã«ãƒ—ãƒƒã‚·ãƒ¥ã—ã¾ã—ã‚‡ã†ã€‚
ä»Šå›ã¯Pythonã‚³ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¦ã¾ã™ãŒã€ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§å®Ÿè¡Œã—ã¦ã‚‚å•é¡Œã‚ã‚Šã¾ã›ã‚“ã€‚

```py
import os
import boto3

# AWSã®ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDã‚’å–å¾—
region     = boto3.session.Session().region_name
account_id = boto3.client('sts').get_caller_identity().get('Account')

# ECRã®ãƒªãƒã‚¸ãƒˆãƒªåã¨ã‚¤ãƒ¡ãƒ¼ã‚¸ã®ã‚¿ã‚°ã‚’è¨­å®š
repository_name = 'whisper-transcribe'
image_tag       = 'GPU'

# Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã®URIã‚’ä½œæˆ
image_uri = f'{account_id}.dkr.ecr.{region}.amazonaws.com/{repository_name}:{image_tag}'

# AWSå…¬å¼ã®Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’Pull
os.system('aws ecr get-login-password --region ap-northeast-1 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.ap-northeast-1.amazonaws.com')
os.system('docker pull 763104351884.dkr.ecr.ap-northeast-1.amazonaws.com/pytorch-inference:2.2.0-gpu-py310')

# Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãƒ“ãƒ«ãƒ‰
os.system(f'docker build -t {repository_name}:{image_tag} .')

# ECRã«ãƒ­ã‚°ã‚¤ãƒ³
os.system(f'$(aws ecr get-login --region {region} --no-include-email)')

# ECRã®ãƒªãƒã‚¸ãƒˆãƒªã‚’ä½œæˆï¼ˆã™ã§ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
os.system(f'aws ecr create-repository --repository-name {repository_name}')

# Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ECRã«ãƒ—ãƒƒã‚·ãƒ¥
os.system(f'docker tag {repository_name}:{image_tag} {image_uri}')
os.system(f'docker push {image_uri}')
```

ã“ã‚Œã§ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ¡ãƒ¼ã‚¸ã®ä½œæˆã¯å®Œäº†ã§ã™ã€‚

### 2. ãƒ¢ãƒ‡ãƒ«ã¨æ¨è«–ã‚³ãƒ¼ãƒ‰ã®æº–å‚™

éåŒæœŸæ¨è«–ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ã¨æ¨è«–ã‚³ãƒ¼ãƒ‰ã‚’ `model.tar.gz` ã¨ã„ã†ãƒ•ã‚¡ã‚¤ãƒ«åã§ã¾ã¨ã‚ã¦S3ã«é…ç½®ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
ã¾ãšã¯æ¨è«–ç”¨ã®ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆã—ã¾ã—ã‚‡ã†ã€‚
SageMaker Endpointã§ã¯ä»¥ä¸‹ã®4ã¤ã®é–¢æ•°ã‚’å®šç¾©ã—ã¾ã™ã€‚

- `model_fn()`
  - `model.tar.gz` ã«ã‚ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹é–¢æ•°ã§ã™ã€‚`model_dir` ã‚’å¼•æ•°ã¨ã—ã¦å—ã‘å–ã‚Šã¾ã™ã€‚ã“ã®é–¢æ•°ã®è¿”ã‚Šå€¤ãŒãã®ã¾ã¾ `predict_fn` ã®ç¬¬äºŒå¼•æ•°ã¨ãªã‚Šã¾ã™ã€‚
- `input_fn()`
  - ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å—ã‘å–ã‚Šã€å‰å‡¦ç†ã‚’è¡Œã†é–¢æ•°ã§ã™ã€‚`input_data` ã¨ `content_type` ã®2ã¤ã‚’å¼•æ•°ã¨ã—ã¦å—ã‘å–ã‚Šã¾ã™ã€‚ã“ã®é–¢æ•°ã®è¿”ã‚Šå€¤ãŒãã®ã¾ã¾ `predict_fn` ã®ç¬¬ä¸€å¼•æ•°ã¨ãªã‚Šã¾ã™ã€‚
- `predict_fn() `
  - æ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹é–¢æ•°ã§ã™ã€‚å¼•æ•°ã«ãã‚Œãã‚Œ `input_fn` ã¨ `model_fn` ã®è¿”ã‚Šå€¤ãŒå…¥ã£ã¦ã„ã¾ã™ã€‚ã“ã®é–¢æ•°ã®è¿”ã‚Šå€¤ãŒãã®ã¾ã¾ `output_fn` ã®ç¬¬ä¸€å¼•æ•°ã¨ãªã‚Šã¾ã™ã€‚
- `output_fn()`
  - æ¨è«–å¾Œã®å¾Œå‡¦ç†ã‚’è¡Œã†é–¢æ•°ã§ã™ã€‚å¼•æ•°ã«ãã‚Œãã‚Œ `predict_fn` ã®è¿”ã‚Šå€¤ã¨ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å½¢å¼(accept)ãŒå…¥ã£ã¦ã„ã¾ã™ã€‚ã“ã®é–¢æ•°ã®è¿”ã‚Šå€¤ãŒæ¨è«–çµæœã¨ã—ã¦S3ã«æ ¼ç´ã•ã‚Œã¾ã™ã€‚

```py: inference.py
import os
import uuid
from faster_whisper import WhisperModel

def model_fn(model_dir):
    model = WhisperModel(
        model_dir,
        device="cuda",
        compute_type="float16"
    )
    return model

def input_fn(input_data, content_type):
    if content_type == 'audio/mpeg':
        os.makedirs('/tmp', exist_ok=True)
        unique_filename = str(uuid.uuid4())
        local_path = f'/tmp/{unique_filename}.mp3'

        with open(local_path, 'wb') as f:
            f.write(input_data)
    else:
        raise ValueError(f"Illegal content type {content_type}. The only allowed content_type is audio/mpeg")

    return local_path

def predict_fn(local_path, model):
    segments, info = model.transcribe(local_path, beam_size=5, vad_filter=True, without_timestamps=True)

    results = []
    for segment in segments:
        result = {
            "start": segment.start,
            "end":   segment.end,
            "text":  segment.text
        }
        results.append(result)
        print(f"[{float(segment.start):.2f}s -> {float(segment.end):.2f}s] {segment.text}")

    return results, local_path

def output_fn(results, accept):
    if accept == 'text/plain':
        transcription_text = "\n".join([segment['text'] for segment in results[0]])
        os.remove(results[1])
        return transcription_text, accept
    else:
        raise ValueError(f"Illegal accept {accept}. The only allowed content_type is text/plain")
```

æ¬¡ã«ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€æ¨è«–ã‚³ãƒ¼ãƒ‰ã¨å…±ã« `model.tar.gz` ã¨ã„ã†åå‰ã§åœ§ç¸®ã—ã¾ã™ã€‚

```py
!pip install faster-whisper==1.0.2
```

```py
import os
from typing import Final
from faster_whisper import download_model

# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•
os.chdir('/home/ec2-user/SageMaker/')

# ãƒ¢ãƒ‡ãƒ«é…ç½®ç”¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã‚’è¨­å®š
model_dir: Final[str] = 'whisper-model'

# ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
model_name = 'large-v3'
download_model(model_name, output_dir=model_dir)

# ãƒ¢ãƒ‡ãƒ«ã®åœ§ç¸®
%cd {model_dir}
!cp ../inference.py ./
!tar zcvf model.tar.gz ./*
%cd ..
```

æœ€å¾Œã«ãƒ¢ãƒ‡ãƒ«ã‚’S3ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ã‚‡ã†ã€‚

```py
# ãƒ¢ãƒ‡ãƒ«ã‚’S3ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
model_s3_uri: Final[str] = sagemaker.Session().upload_data(
    f'./{model_dir}/model.tar.gz',
    key_prefix='whisper-transcribe'
)
print(model_s3_uri)
```

ã“ã‚Œã§ãƒ¢ãƒ‡ãƒ«ã¨æ¨è«–ã‚³ãƒ¼ãƒ‰ã®æº–å‚™ã‚‚å®Œäº†ã§ã™ã€‚

### 3. ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ä½œæˆï¼ˆãƒ‡ãƒ—ãƒ­ã‚¤ï¼‰

ã“ã“ã‹ã‚‰ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ä½œæˆã—ã¦ã„ãã¾ã™ã€‚
ã¾ãšã¯å¿…è¦ã¨ãªã‚‹ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ»å¤‰æ•°ã‚’å®šç¾©ã—ã¾ã™ã€‚

```py
import os
import boto3
import sagemaker
from typing import Final
from time import sleep

# å„ç¨®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®è¨­å®š
smr_client:      Final = boto3.client('sagemaker-runtime')
sm_client:       Final = boto3.client('sagemaker')
s3_client:       Final = boto3.client('s3')
endpoint_waiter: Final = sm_client.get_waiter('endpoint_in_service')

# å„ç¨®å¤‰æ•°ã®è¨­å®š
role:       Final[str] = sagemaker.get_execution_role()
region:     Final[str] = sagemaker.Session().boto_region_name
bucket:     Final[str] = sagemaker.Session().default_bucket()
account_id: Final[str] = boto3.client('sts').get_caller_identity().get('Account')

# ãƒ‡ãƒ—ãƒ­ã‚¤ãƒªã‚½ãƒ¼ã‚¹åã®è¨­å®š
model_name:           Final[str] = 'WhisperTranscribeModel'
variant_name:         Final[str] = 'AllTrafic'
endpoint_name:        Final[str] = model_name + 'Endpoint'
endpoint_config_name: Final[str] = model_name + 'EndpointConfig'
```

æ¬¡ã«ãƒ¢ãƒ‡ãƒ«ã¨æ¨è«–ç’°å¢ƒï¼ˆæ¨è«–ã‚³ãƒ¼ãƒ‰ã‚„ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã€ç’°å¢ƒå¤‰æ•°ã®è¨­å®šï¼‰ã‚’ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åŒ–ã—ãŸSageMaker Modelã‚’ä½œæˆã—ã¾ã™ã€‚

```py
# Sagemaker Model ä½œæˆ
sm_client.create_model(
    ModelName=model_name,
    PrimaryContainer={
        'Image': f'{account_id}.dkr.ecr.{region}.amazonaws.com/whisper-transcribe:GPU',
        'ModelDataUrl': model_s3_uri,
        'Environment': {
            'SAGEMAKER_CONTAINER_LOG_LEVEL': '20',
            'SAGEMAKER_PROGRAM':             'inference.py',
            'SAGEMAKER_REGION':              region,
            'SAGEMAKER_SUBMIT_DIRECTORY':    '/opt/ml/model/code',
            'TS_MAX_REQUEST_SIZE':           '1000000000',
            'TS_MAX_RESPONSE_SIZE':          '1000000000',
            'TS_DEFAULT_RESPONSE_TIMEOUT':   '3600'
        }
    },
    ExecutionRoleArn=role,
)
```

æ¬¡ã«Sagemaker EndpointConfigã‚’ä½œæˆã—ã¾ã™ã€‚
ã“ã‚Œã¯ä½¿ç”¨ã™ã‚‹SageMaker Modelã‚„ã€æ¨è«–ã«ä½¿ã†ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒªã‚½ãƒ¼ã‚¹ï¼ˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—ã€å°æ•°ãªã©ï¼‰ã‚’è¨­å®šã™ã‚‹ãŸã‚ã®ã‚‚ã®ã§ã™ã€‚

```py
# Sagemaker EndpointConfig ä½œæˆ
sm_client.create_endpoint_config(
    EndpointConfigName=endpoint_config_name,
    ProductionVariants=[
        {
            'VariantName':          variant_name,
            'ModelName':            model_name,
            'InitialInstanceCount': 1,
            'InstanceType':         'ml.g4dn.xlarge'
        }
    ],
    AsyncInferenceConfig={
        "OutputConfig": {
            "S3OutputPath": f"s3://{bucket}/whisper-transcribe/async-inference/output"
        }
    }
)
```

æœ€å¾Œã«EndpointConfigã®è¨­å®šã‚’å…ƒã«ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ä½œæˆï¼ˆãƒ‡ãƒ—ãƒ­ã‚¤ï¼‰ã‚’è¡Œã„ã¾ã™ã€‚
create_endpointã¯éåŒæœŸAPIãªã®ã§ã€endpoint_waiter.waitã§ä½œæˆå®Œäº†ã‚’å¾…ã£ã¦ã„ã¾ã™ã€‚

```py
# éåŒæœŸ Endpoint ä½œæˆ
sm_client.create_endpoint(
    EndpointName=endpoint_name,
    EndpointConfigName=endpoint_config_name,
)
# Endpoint ãŒæœ‰åŠ¹åŒ–ã•ã‚Œã‚‹ã¾ã§å¾…ã¤
endpoint_waiter.wait(
    EndpointName=endpoint_name,
    WaiterConfig={'Delay': 5}
)
```

ã“ã‚Œã§ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ä½œæˆã¯å®Œäº†ã§ã™ï¼
å®Ÿéš›ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã—ã¦ã¿ã‚‹ã¨ã€ä¸€å®šæ™‚é–“ãŒçµŒéã—ãŸã®ã¡ã«OutputConfigã§è¨­å®šã—ãŸS3ãƒã‚±ãƒƒãƒˆãƒ‘ã‚¹ã«æ¨è«–çµæœãŒãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦æ ¼ç´ã•ã‚Œã¦ã„ã‚‹ã¨æ€ã„ã¾ã™ã€‚
(input_dataã¯ã‚ã‚‰ã‹ã˜ã‚S3ã«æ ¼ç´ã—ã¦ãŠãã¾ã—ã‚‡ã†)

```py
# éåŒæœŸ Endpoint å‘¼ã³å‡ºã—
response = smr_client.invoke_endpoint_async(
    EndpointName=endpoint_name,
    InputLocation=f"s3://{bucket}/whisper-transcribe/async-inference/input/input_data.mp3",
    ContentType='audio/mpeg',
    Accept='text/plain'
)

# S3ã«ä¿å­˜ã•ã‚Œã‚‹ã¾ã§ãƒãƒ¼ãƒªãƒ³ã‚°
output_s3_uri = response['OutputLocation']
output_key    = output_s3_uri.replace(f's3://{bucket}/', '')
while True:
    result = s3_client.list_objects(Bucket=bucket, Prefix=output_key)
    exists = True if "Contents" in result else False
    if exists:
        print('!')
        obj         = s3_client.get_object(Bucket=bucket, Key=output_key)
        predictions = obj['Body'].read().decode()
        print(predictions)
        break
    else:
        print('.', end='')
        sleep(0.1)
```

SageMakerç‰¹æœ‰ã®ãƒ«ãƒ¼ãƒ«ãŒå¤šãã¦çµæ§‹å¤§å¤‰ã§ã—ãŸãŒã€ã“ã‚Œã§ç„¡äº‹æ–‡å­—èµ·ã“ã—ç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ä½œæˆã¯å®Œäº†ã§ã™ã€‚

### 4. ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒ«è¨­å®š

ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®æ§‹ç¯‰ã¯å®Œäº†ã—ã¾ã—ãŸãŒã€æœ€å¾Œã«ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒ«ã®è¨­å®šã‚’è¡Œã„ã¾ã™ã€‚
ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒ«ã®è¨­å®šã«ã‚ˆã‚Šã€ä½¿ç”¨ã—ã¦ã„ãªã„æ™‚é–“å¸¯ã«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®å¯å‹•å°æ•°ã‚’0ã«ã§ãã‚‹ã®ã§ã€ã‚³ã‚¹ãƒˆã®å‰Šæ¸›ã«ç¹‹ãŒã‚Šã¾ã™ã€‚

Amazon SageMakerã§ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒãƒªã‚·ãƒ¼ã¯ä¸»ã«ä»¥ä¸‹ã®2ã¤ã®ã‚¿ã‚¤ãƒ—ãŒã‚ã‚Šã¾ã™ï¼š

- `TargetTrackingScaling`
  - ã“ã®ã‚¿ã‚¤ãƒ—ã§ã¯CloudWatchã‚¢ãƒ©ãƒ¼ãƒ ã®è¨­å®šã¯å¿…è¦ãªãã€ç‰¹å®šã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãŒç›®æ¨™å€¤ã‚’ç¶­æŒã™ã‚‹ã‚ˆã†ã«AWSãŒè‡ªå‹•çš„ã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã—ã¾ã™ã€‚(è£ã§è‡ªå‹•ã§CloudWatchã‚¢ãƒ©ãƒ¼ãƒ ãŒä½œæˆã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã§ã™)
- `StepScaling`
  - ã“ã®ã‚¿ã‚¤ãƒ—ã§ã¯CloudWatchã‚¢ãƒ©ãƒ¼ãƒ ã®è¨­å®šãŒå¿…è¦ã§ã€ç‰¹å®šã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã«åŸºã¥ã„ã¦ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’ãƒˆãƒªã‚¬ãƒ¼ã™ã‚‹ã‚ˆã†è‡ªåˆ†ã§è¨­å®šã‚’è¡Œã„ã¾ã™ã€‚

åŸºæœ¬çš„ã«ã¯TargetTrackingScalingãŒæ¨å¥¨ã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã§ã™ãŒã€ã‚¹ã‚±ãƒ¼ãƒ«ã‚¤ãƒ³ãŒå°‘ã—é…ã„æ°—ãŒã—ãŸã®ã§StepScalingã§æ§‹ç¯‰ã—ã¾ã™ã€‚
ã“ã“ã§ã¯ä»¥ä¸‹ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

- `ApproximateBacklogSize`
- `HasBacklogWithoutCapacity`

è©³ç´°ã‚„ã€éåŒæœŸæ¨è«–ã§ä½¿ç”¨ã§ãã‚‹ãã®ä»–ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã«é–¢ã—ã¦ã¯ä»¥ä¸‹ã®ãƒªãƒ³ã‚¯ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚
https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/async-inference-monitor.html#async-inference-monitor-cloudwatch-async

ã¾ãšã¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«å¯¾ã™ã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°è¨­å®šã‚’è¡Œã„ã¾ã™ã€‚
ã“ã“ã§ã¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ•°ã‚’0ã‹ã‚‰1ã¾ã§ã®ç¯„å›²ã§ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã™ã‚‹ã‚ˆã†ã«è¨­å®šã—ã¦ã„ã¾ã™ã€‚

```py
as_client: Final = boto3.client('application-autoscaling')
cw_client: Final = boto3.client('cloudwatch')

# ResourceIdã®è¨­å®š
resource_id = f'endpoint/{endpoint_name}/variant/{variant_name}'

# ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°è¨­å®šã‚’ç™»éŒ²
as_client.register_scalable_target(
    ServiceNamespace='sagemaker',
    ResourceId=resource_id,
    ScalableDimension='sagemaker:variant:DesiredInstanceCount',
    MinCapacity=0,
    MaxCapacity=1
)
```

æ¬¡ã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒãƒªã‚·ãƒ¼ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚¢ãƒ©ãƒ¼ãƒ ã®è¨­å®šã‚’è¡Œã„ã¾ã™ã€‚

```py:ApproximateBacklogSizeç›£è¦–ç”¨(ã‚¹ã‚±ãƒ¼ãƒ«ã‚¤ãƒ³[1 â†’ 0])
# ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒãƒªã‚·ãƒ¼ã®è¨­å®š
response = as_client.put_scaling_policy(
    PolicyName="ApproximateBacklogSize-ScalingPolicy",
    ServiceNamespace="sagemaker",
    ResourceId=resource_id,
    ScalableDimension="sagemaker:variant:DesiredInstanceCount",
    PolicyType="StepScaling",
    StepScalingPolicyConfiguration={
        "AdjustmentType": "ChangeInCapacity",
        "MetricAggregationType": "Average",
        "Cooldown": 300,
        "StepAdjustments": [
            {
                "MetricIntervalUpperBound": 1,
                "ScalingAdjustment": -1
            }
        ]
    }
)
scaling_policy_arn = response['PolicyARN']

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚¢ãƒ©ãƒ¼ãƒ ã®è¨­å®š
cw_client.put_metric_alarm(
    AlarmName='ScaleInAlarm-ApproximateBacklogSize',
    MetricName='ApproximateBacklogSizePerInstance',
    Namespace='AWS/SageMaker',
    Statistic='Average',
    EvaluationPeriods=1,
    DatapointsToAlarm=1,
    Threshold=1,
    ComparisonOperator='LessThanThreshold',
    TreatMissingData='missing',
    Dimensions=[
        {'Name': 'EndpointName', 'Value': endpoint_name}
    ],
    Period=60,
    AlarmActions=[scaling_policy_arn]
)
```

```py:HasBacklogWithoutCapacityç›£è¦–ç”¨(ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆ[0 â†’ 1])
# ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒãƒªã‚·ãƒ¼ã®è¨­å®š
response = as_client.put_scaling_policy(
    PolicyName="HasBacklogWithoutCapacity-ScalingPolicy",
    ServiceNamespace="sagemaker",
    ResourceId=resource_id,
    ScalableDimension="sagemaker:variant:DesiredInstanceCount",
    PolicyType="StepScaling",
    StepScalingPolicyConfiguration={
        "AdjustmentType": "ChangeInCapacity",
        "MetricAggregationType": "Average",
        "Cooldown": 300,
        "StepAdjustments":
            [
                {
                    "MetricIntervalLowerBound": 0,
                    "ScalingAdjustment": 1
                }
            ]
    }
)
scaling_policy_arn = response['PolicyARN']

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚¢ãƒ©ãƒ¼ãƒ ã®è¨­å®š
cw_client.put_metric_alarm(
    AlarmName='ScaleOutAlarm-HasBacklogWithoutCapacity',
    MetricName='HasBacklogWithoutCapacity',
    Namespace='AWS/SageMaker',
    Statistic='Average',
    EvaluationPeriods=1,
    DatapointsToAlarm=1,
    Threshold=1,
    ComparisonOperator='GreaterThanOrEqualToThreshold',
    TreatMissingData='missing',
    Dimensions=[
        {'Name': 'EndpointName', 'Value': endpoint_name}
    ],
    Period=60,
    AlarmActions=[scaling_policy_arn]
)
```

ã“ã‚Œã§ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒ«ã‚’å«ã‚€å…¨ã¦ã®è¨­å®šãŒå®Œäº†ã—ã¾ã—ãŸï¼

æ›´ãªã‚‹é€Ÿåº¦ã®æ”¹å–„æ¡ˆã‚„ã€ã‚ˆã‚Šè‰¯ã„ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°è¨­å®šãªã©ãŒã‚ã‚Šã¾ã—ãŸã‚‰ã€ãœã²ã‚³ãƒ¡ãƒ³ãƒˆã§æ•™ãˆã¦ãã ã•ã„ã€‚
æœ€å¾Œã¾ã§èª­ã‚“ã§ã„ãŸã ãã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚
